{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a2de98e-68dc-4136-8a23-77a200d02843",
   "metadata": {},
   "source": [
    "# PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5f77cd-0de0-4e74-af31-0b4b9b2fb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "background_map = {\n",
    "    'The city of London': 'The city of London',\n",
    "    'The Parthenon in front of the Great Pyramid': 'The Parthenon in front of the Great Pyramid',\n",
    "    'A single beam of light enters the room from the ceiling The beam of light is illuminating an easel On the easel there is a Rembrandt painting of a raccoon': 'A single beam of light enters the room from the ceiling. The beam of light is illuminating an easel. On the easel, there is a Rembrandt painting of a raccoon.',\n",
    "    'A sunset': 'A sunset',\n",
    "    'Photograph of a wall along a city street with a watercolor mural of foes in a jazz band': 'Photograph of a wall along a city street with a watercolor mural of foxes in a jazz band.'\n",
    "}\n",
    "\n",
    "clothes_map = {\n",
    "    'A_scientist': 'A scientist',\n",
    "    'A_photograph_of_a_knight_in_shining_armor_holding_a_basketball': 'A photograph of a knight in shining armor holding a basketball',\n",
    "    'The_Mona_Lisa': 'The Mona Lisa',\n",
    "    'Salvador_Dalí': 'Salvador Dalí',\n",
    "    'A_person_with_arms_like_a_tree_branch': 'A person with arms like a tree branch'\n",
    "}\n",
    "\n",
    "def parse_threshold(th_str: str) -> float:\n",
    "    return int(th_str[2:]) / 10.0\n",
    "\n",
    "rows = []\n",
    "for file in sorted(Path('experiment').glob('*.jpg')):\n",
    "    name = file.name\n",
    "    parts = name[:-4].split('__')\n",
    "    img_name = parts[0]\n",
    "    background_raw = parts[2]\n",
    "    th_raw = parts[3]\n",
    "    clothing_raw = parts[4]\n",
    "    row = {\n",
    "        'nome_arquivo': name,\n",
    "        'imagem': img_name,\n",
    "        'threshold': parse_threshold(th_raw),\n",
    "        'prompt_fundo': background_map.get(background_raw, background_raw),\n",
    "        'prompt_roupa': clothes_map.get(clothing_raw, clothing_raw.replace('_', ' '))\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1de5b6a-1f45-4168-ace7-d89507befffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processando 6000 imagens para PSNR...\n",
      "[INFO] 300/6000 concluídas...\n",
      "[INFO] 600/6000 concluídas...\n",
      "[INFO] 900/6000 concluídas...\n",
      "[INFO] 1200/6000 concluídas...\n",
      "[INFO] 1500/6000 concluídas...\n",
      "[INFO] 1800/6000 concluídas...\n",
      "[INFO] 2100/6000 concluídas...\n",
      "[INFO] 2400/6000 concluídas...\n",
      "[INFO] 2700/6000 concluídas...\n",
      "[INFO] 3000/6000 concluídas...\n",
      "[INFO] 3300/6000 concluídas...\n",
      "[INFO] 3600/6000 concluídas...\n",
      "[INFO] 3900/6000 concluídas...\n",
      "[INFO] 4200/6000 concluídas...\n",
      "[INFO] 4500/6000 concluídas...\n",
      "[INFO] 4800/6000 concluídas...\n",
      "[INFO] 5100/6000 concluídas...\n",
      "[INFO] 5400/6000 concluídas...\n",
      "[INFO] 5700/6000 concluídas...\n",
      "[INFO] 6000/6000 concluídas...\n",
      "[FINALIZADO] PSNR salvo/mesclado em: experiment_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PSNR por imagem (duas colunas): psnr_fundo e psnr_inpainting.\n",
    "- Muito mais rápido que FID (não usa rede neural).\n",
    "- Se houver múltiplas referências por prompt, tira a MÉDIA dos PSNRs.\n",
    "- Opcional: filtrar por threshold (ex.: 1.3).\n",
    "\n",
    "Saída: acrescenta colunas 'psnr_fundo' e 'psnr_inpainting' em experiment_metrics.csv.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, math, unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import regex as re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "EXPERIMENT_DIR = Path(\"experiment\")\n",
    "CSV_IN = None               # None = usar df do ambiente; ou \"experiment.csv\"\n",
    "CSV_OUT = \"experiment_metrics.csv\"\n",
    "RESIZE_TO = None            # ex.: (512, 512) para padronizar e acelerar; None = manter tamanho do gerado\n",
    "TARGET_THRESHOLD = None     # ex.: 1.3 para filtrar; None = não filtra\n",
    "\n",
    "# Mapeamento: prompt -> caminho(s) de referência\n",
    "REFERENCE_IMAGES: Dict[str, Union[str, List[str]]] = {\n",
    "    'Photograph of a wall along a city street with a watercolor mural of foxes in a jazz band.': 'reference_images/fox_mural.png',\n",
    "    'The city of London': 'reference_images/london.png',\n",
    "    'The Parthenon in front of the Great Pyramid': 'reference_images/partenon_great_pyramid.png',\n",
    "    'A sunset': 'reference_images/sunset.png',\n",
    "    'A single beam of light enters the room from the ceiling. The beam of light is illuminating an easel. On the easel, there is a Rembrandt painting of a raccoon.': 'reference_images/racoon.png',\n",
    "    'A scientist': 'reference_images/scientist.png',\n",
    "    'A photograph of a knight in shining armor holding a basketball': 'reference_images/knight_basketball.png',\n",
    "    'The Mona Lisa': 'reference_images/monalisa.jpg',\n",
    "    'Salvador Dalí': 'reference_images/salvador_dali.jpeg',\n",
    "    'A person with arms like a tree branch': 'reference_images/tree_arms.png',\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _expand_paths(entry: Union[str, List[str]]) -> List[Path]:\n",
    "    \"\"\"Aceita string ou lista; inclui *_2.ext se existir.\"\"\"\n",
    "    entries = [entry] if isinstance(entry, str) else list(entry)\n",
    "    out: List[Path] = []\n",
    "    seen = set()\n",
    "    for e in entries:\n",
    "        p = Path(e)\n",
    "        for cand in (p, p.with_name(f\"{p.stem}_2{p.suffix}\")):\n",
    "            if cand.exists():\n",
    "                key = str(cand.resolve()) if cand.exists() else str(cand)\n",
    "                if key not in seen:\n",
    "                    out.append(cand)\n",
    "                    seen.add(key)\n",
    "    return out\n",
    "\n",
    "_punct = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "def _norm(s: str) -> str:\n",
    "    s = str(s).replace(\"_\", \" \")\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    s = _punct.sub(\" \", s).lower().strip()\n",
    "    s = \" \".join(s.split())\n",
    "    return s\n",
    "\n",
    "def build_ref_map(mapping: Dict[str, Union[str, List[str]]]) -> Dict[str, List[Path]]:\n",
    "    out: Dict[str, List[Path]] = {}\n",
    "    for k, v in mapping.items():\n",
    "        out[_norm(k)] = _expand_paths(v)\n",
    "    return out\n",
    "\n",
    "def find_refs(prompt: str, ref_map: Dict[str, List[Path]]) -> List[Path]:\n",
    "    key = _norm(prompt)\n",
    "    # exato\n",
    "    if key in ref_map and ref_map[key]:\n",
    "        return ref_map[key]\n",
    "    # substring\n",
    "    for k, paths in ref_map.items():\n",
    "        if paths and (key in k or k in key):\n",
    "            return paths\n",
    "    return []\n",
    "\n",
    "def psnr(img_a: np.ndarray, img_b: np.ndarray, data_range: float = 255.0) -> float:\n",
    "    \"\"\"PSNR em dB (quanto MAIOR, melhor). img_*: uint8 ou float32 [0..255].\"\"\"\n",
    "    a = img_a.astype(np.float32)\n",
    "    b = img_b.astype(np.float32)\n",
    "    mse = np.mean((a - b) ** 2)\n",
    "    if mse <= 1e-12:\n",
    "        return float('inf')\n",
    "    return 20.0 * math.log10(data_range / math.sqrt(mse))\n",
    "\n",
    "def load_img(path: Path, resize_to: Optional[Tuple[int, int]]) -> np.ndarray:\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    if resize_to is not None:\n",
    "        im = im.resize(resize_to, Image.BILINEAR)\n",
    "    return np.array(im, dtype=np.uint8)\n",
    "\n",
    "def parse_threshold_from_name(name: str) -> Optional[float]:\n",
    "    s = str(name)\n",
    "    m = re.search(r'__th([0-9]+(?:\\.[0-9]+)?)__', s, flags=re.IGNORECASE) \\\n",
    "        or re.search(r'_th([0-9]+(?:\\.[0-9]+)?)_', s, flags=re.IGNORECASE) \\\n",
    "        or re.search(r'th([0-9]+(?:\\.[0-9]+)?)', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        try: return float(m.group(1))\n",
    "        except: pass\n",
    "    m2 = re.search(r'__th([0-9]{1,3})__', s, flags=re.IGNORECASE) \\\n",
    "         or re.search(r'_th([0-9]{1,3})_', s, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        d = m2.group(1)\n",
    "        if d.isdigit():\n",
    "            if len(d) == 1: return float(d)/10.0\n",
    "            if len(d) == 2: return float(f\"{d[0]}.{d[1]}\")\n",
    "            if len(d) == 3: return float(f\"{d[0]}.{d[1:3]}\")\n",
    "            return float(d)\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# Carrega df\n",
    "# =========================\n",
    "if CSV_IN is None:\n",
    "    if 'df' in globals():\n",
    "        df_base = df.copy()\n",
    "    elif 'df_out' in globals():\n",
    "        df_base = df_out.copy()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Nem 'df' nem 'df_out' estão no ambiente. Defina CSV_IN para ler de arquivo.\")\n",
    "else:\n",
    "    df_base = pd.read_csv(CSV_IN)\n",
    "\n",
    "req = {\"nome_arquivo\", \"prompt_roupa\", \"prompt_fundo\"}\n",
    "miss = req - set(df_base.columns)\n",
    "if miss:\n",
    "    raise ValueError(f\"DataFrame não contém: {miss}\")\n",
    "\n",
    "# Extrai threshold (se quiser filtrar)\n",
    "if TARGET_THRESHOLD is not None:\n",
    "    if \"threshold\" in df_base.columns:\n",
    "        th_series = pd.to_numeric(df_base[\"threshold\"], errors=\"coerce\")\n",
    "    else:\n",
    "        th_series = df_base[\"nome_arquivo\"].map(parse_threshold_from_name)\n",
    "    df_base = df_base.assign(_th_val=th_series)\n",
    "    before = len(df_base)\n",
    "    df_base = df_base[np.isfinite(df_base[\"_th_val\"]) & (np.isclose(df_base[\"_th_val\"], float(TARGET_THRESHOLD)))]\n",
    "    print(f\"[INFO] Filtradas {len(df_base)}/{before} linhas para threshold={TARGET_THRESHOLD}\")\n",
    "\n",
    "# =========================\n",
    "# Loop PSNR\n",
    "# =========================\n",
    "ref_map = build_ref_map(REFERENCE_IMAGES)\n",
    "psnr_fundo, psnr_inp = [], []\n",
    "\n",
    "print(f\"[INFO] Processando {len(df_base)} imagens para PSNR...\")\n",
    "for i, row in df_base.iterrows():\n",
    "    img_path = EXPERIMENT_DIR / str(row[\"nome_arquivo\"])\n",
    "    if not img_path.exists():\n",
    "        print(f\"[AVISO] ausente: {img_path}\")\n",
    "        psnr_fundo.append(np.nan)\n",
    "        psnr_inp.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # carrega imagem gerada\n",
    "    img_arr = load_img(img_path, RESIZE_TO)\n",
    "\n",
    "    # refs fundo\n",
    "    fundo_refs = find_refs(str(row[\"prompt_fundo\"]), ref_map)\n",
    "    if not fundo_refs:\n",
    "        print(f\"[AVISO] sem ref fundo para: {row['prompt_fundo']}\")\n",
    "        psnr_fundo.append(np.nan)\n",
    "    else:\n",
    "        vals = []\n",
    "        for rp in fundo_refs:\n",
    "            ref_arr = load_img(rp, RESIZE_TO if RESIZE_TO else img_arr.shape[1::-1])\n",
    "            # ajusta tamanho da ref ao da gerada, se necessário\n",
    "            if ref_arr.shape != img_arr.shape:\n",
    "                pil_ref = Image.fromarray(ref_arr)\n",
    "                pil_ref = pil_ref.resize((img_arr.shape[1], img_arr.shape[0]), Image.BILINEAR)\n",
    "                ref_arr = np.array(pil_ref, dtype=np.uint8)\n",
    "            vals.append(psnr(img_arr, ref_arr))\n",
    "        psnr_fundo.append(float(np.mean(vals)))\n",
    "\n",
    "    # refs inpainting\n",
    "    inp_refs = find_refs(str(row[\"prompt_roupa\"]), ref_map)\n",
    "    if not inp_refs:\n",
    "        print(f\"[AVISO] sem ref inpainting para: {row['prompt_roupa']}\")\n",
    "        psnr_inp.append(np.nan)\n",
    "    else:\n",
    "        vals = []\n",
    "        for rp in inp_refs:\n",
    "            ref_arr = load_img(rp, RESIZE_TO if RESIZE_TO else img_arr.shape[1::-1])\n",
    "            if ref_arr.shape != img_arr.shape:\n",
    "                pil_ref = Image.fromarray(ref_arr)\n",
    "                pil_ref = pil_ref.resize((img_arr.shape[1], img_arr.shape[0]), Image.BILINEAR)\n",
    "                ref_arr = np.array(pil_ref, dtype=np.uint8)\n",
    "            vals.append(psnr(img_arr, ref_arr))\n",
    "        psnr_inp.append(float(np.mean(vals)))\n",
    "\n",
    "    if (len(psnr_fundo) % max(1, len(df_base)//20)) == 0:\n",
    "        print(f\"[INFO] {len(psnr_fundo)}/{len(df_base)} concluídas...\")\n",
    "\n",
    "# =========================\n",
    "# Salva\n",
    "# =========================\n",
    "df_out_psnr = df_base.copy()\n",
    "df_out_psnr[\"psnr_fundo\"] = psnr_fundo\n",
    "df_out_psnr[\"psnr_inpainting\"] = psnr_inp\n",
    "\n",
    "# Se já existe um experiment_metrics.csv com outras métricas, fazemos merge por nome_arquivo\n",
    "try:\n",
    "    if Path(CSV_OUT).exists():\n",
    "        old = pd.read_csv(CSV_OUT)\n",
    "        merged = old.merge(\n",
    "            df_out_psnr[[\"nome_arquivo\", \"psnr_fundo\", \"psnr_inpainting\"]],\n",
    "            on=\"nome_arquivo\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        merged.to_csv(CSV_OUT, index=False)\n",
    "        print(f\"[FINALIZADO] PSNR salvo/mesclado em: {CSV_OUT}\")\n",
    "    else:\n",
    "        df_out_psnr.to_csv(CSV_OUT, index=False)\n",
    "        print(f\"[FINALIZADO] PSNR salvo em: {CSV_OUT}\")\n",
    "except Exception as e:\n",
    "    df_out_psnr.to_csv(CSV_OUT, index=False)\n",
    "    print(f\"[FINALIZADO] PSNR salvo (modo fallback) em: {CSV_OUT}. Motivo do fallback: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44708e5-c289-4885-8c39-d2697a48daeb",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f33b177c-a3f3-4363-bab8-4785fad7b0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processando 6000 imagens para SSIM...\n",
      "[INFO] 300/6000 concluídas...\n",
      "[INFO] 600/6000 concluídas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "SSIM por imagem (duas colunas): ssim_fundo e ssim_inpainting.\n",
    "- Muito rápido (apenas operações por pixel/janela), sem redes neurais.\n",
    "- Se houver múltiplas referências por prompt, tira a MÉDIA dos SSIMs.\n",
    "- Opcional: filtrar por threshold (ex.: 1.3).\n",
    "\n",
    "Saída: acrescenta colunas 'ssim_fundo' e 'ssim_inpainting' em experiment_metrics.csv.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import regex as re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "EXPERIMENT_DIR = Path(\"experiment\")\n",
    "CSV_IN = None               # None = usar df/df_out do ambiente; ou ex.: \"experiment.csv\"\n",
    "CSV_OUT = \"experiment_metrics.csv\"\n",
    "RESIZE_TO = None            # ex.: (512, 512) para padronizar; None = manter tamanho do gerado\n",
    "TARGET_THRESHOLD = None     # ex.: 1.3 para filtrar; None = não filtra\n",
    "\n",
    "# Mapeamento: prompt -> caminho(s) de referência\n",
    "REFERENCE_IMAGES: Dict[str, Union[str, List[str]]] = {\n",
    "    'Photograph of a wall along a city street with a watercolor mural of foxes in a jazz band.': 'reference_images/fox_mural.png',\n",
    "    'The city of London': 'reference_images/london.png',\n",
    "    'The Parthenon in front of the Great Pyramid': 'reference_images/partenon_great_pyramid.png',\n",
    "    'A sunset': 'reference_images/sunset.png',\n",
    "    'A single beam of light enters the room from the ceiling. The beam of light is illuminating an easel. On the easel, there is a Rembrandt painting of a raccoon.': 'reference_images/racoon.png',\n",
    "    'A scientist': 'reference_images/scientist.png',\n",
    "    'A photograph of a knight in shining armor holding a basketball': 'reference_images/knight_basketball.png',\n",
    "    'The Mona Lisa': 'reference_images/monalisa.jpg',\n",
    "    'Salvador Dalí': 'reference_images/salvador_dali.jpeg',\n",
    "    'A person with arms like a tree branch': 'reference_images/tree_arms.png',\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _expand_paths(entry: Union[str, List[str]]) -> List[Path]:\n",
    "    \"\"\"Aceita string ou lista; inclui *_2.ext se existir.\"\"\"\n",
    "    entries = [entry] if isinstance(entry, str) else list(entry)\n",
    "    out: List[Path] = []\n",
    "    seen = set()\n",
    "    for e in entries:\n",
    "        p = Path(e)\n",
    "        for cand in (p, p.with_name(f\"{p.stem}_2{p.suffix}\")):\n",
    "            if cand.exists():\n",
    "                key = str(cand.resolve()) if cand.exists() else str(cand)\n",
    "                if key not in seen:\n",
    "                    out.append(cand)\n",
    "                    seen.add(key)\n",
    "    return out\n",
    "\n",
    "_punct = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "def _norm(s: str) -> str:\n",
    "    s = str(s).replace(\"_\", \" \")\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    s = _punct.sub(\" \", s).lower().strip()\n",
    "    s = \" \".join(s.split())\n",
    "    return s\n",
    "\n",
    "def build_ref_map(mapping: Dict[str, Union[str, List[str]]]) -> Dict[str, List[Path]]:\n",
    "    out: Dict[str, List[Path]] = {}\n",
    "    for k, v in mapping.items():\n",
    "        out[_norm(k)] = _expand_paths(v)\n",
    "    return out\n",
    "\n",
    "def find_refs(prompt: str, ref_map: Dict[str, List[Path]]) -> List[Path]:\n",
    "    key = _norm(prompt)\n",
    "    # exato\n",
    "    if key in ref_map and ref_map[key]:\n",
    "        return ref_map[key]\n",
    "    # substring\n",
    "    for k, paths in ref_map.items():\n",
    "        if paths and (key in k or k in key):\n",
    "            return paths\n",
    "    return []\n",
    "\n",
    "def load_img(path: Path, resize_to: Optional[Tuple[int, int]]) -> np.ndarray:\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    if resize_to is not None:\n",
    "        im = im.resize(resize_to, Image.BILINEAR)\n",
    "    return np.array(im, dtype=np.uint8)\n",
    "\n",
    "def ssim_img(img_a: np.ndarray, img_b: np.ndarray) -> float:\n",
    "    \"\"\"SSIM ∈ [0,1], maior é melhor. img_* devem estar em uint8 [0..255].\"\"\"\n",
    "    from skimage.metrics import structural_similarity as ssim\n",
    "    # Ajuste de shape/tamanho\n",
    "    if img_a.shape != img_b.shape:\n",
    "        pil_b = Image.fromarray(img_b)\n",
    "        pil_b = pil_b.resize((img_a.shape[1], img_a.shape[0]), Image.BILINEAR)\n",
    "        img_b = np.array(pil_b, dtype=np.uint8)\n",
    "    # Compatibilidade com versões de skimage\n",
    "    try:\n",
    "        val = ssim(img_a, img_b, data_range=255, channel_axis=-1,\n",
    "                   gaussian_weights=True, sigma=1.5, use_sample_covariance=False)\n",
    "    except TypeError:\n",
    "        # versões antigas\n",
    "        val = ssim(img_a, img_b, data_range=255, multichannel=True,\n",
    "                   gaussian_weights=True, sigma=1.5, use_sample_covariance=False)\n",
    "    return float(val)\n",
    "\n",
    "def parse_threshold_from_name(name: str) -> Optional[float]:\n",
    "    s = str(name)\n",
    "    m = re.search(r'__th([0-9]+(?:\\.[0-9]+)?)__', s, flags=re.IGNORECASE) \\\n",
    "        or re.search(r'_th([0-9]+(?:\\.[0-9]+)?)_', s, flags=re.IGNORECASE) \\\n",
    "        or re.search(r'th([0-9]+(?:\\.[0-9]+)?)', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        try: return float(m.group(1))\n",
    "        except: pass\n",
    "    m2 = re.search(r'__th([0-9]{1,3})__', s, flags=re.IGNORECASE) \\\n",
    "         or re.search(r'_th([0-9]{1,3})_', s, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        d = m2.group(1)\n",
    "        if d.isdigit():\n",
    "            if len(d) == 1: return float(d)/10.0\n",
    "            if len(d) == 2: return float(f\"{d[0]}.{d[1]}\")\n",
    "            if len(d) == 3: return float(f\"{d[0]}.{d[1:3]}\")\n",
    "            return float(d)\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# Carrega df\n",
    "# =========================\n",
    "if CSV_IN is None:\n",
    "    if 'df' in globals():\n",
    "        df_base = df.copy()\n",
    "    elif 'df_out' in globals():\n",
    "        df_base = df_out.copy()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Nem 'df' nem 'df_out' estão no ambiente. Defina CSV_IN para ler de arquivo.\")\n",
    "else:\n",
    "    df_base = pd.read_csv(CSV_IN)\n",
    "\n",
    "req = {\"nome_arquivo\", \"prompt_roupa\", \"prompt_fundo\"}\n",
    "miss = req - set(df_base.columns)\n",
    "if miss:\n",
    "    raise ValueError(f\"DataFrame não contém: {miss}\")\n",
    "\n",
    "# Extrai threshold (se quiser filtrar)\n",
    "if TARGET_THRESHOLD is not None:\n",
    "    if \"threshold\" in df_base.columns:\n",
    "        th_series = pd.to_numeric(df_base[\"threshold\"], errors=\"coerce\")\n",
    "    else:\n",
    "        th_series = df_base[\"nome_arquivo\"].map(parse_threshold_from_name)\n",
    "    df_base = df_base.assign(_th_val=th_series)\n",
    "    before = len(df_base)\n",
    "    df_base = df_base[np.isfinite(df_base[\"_th_val\"]) & (np.isclose(df_base[\"_th_val\"], float(TARGET_THRESHOLD)))]\n",
    "    print(f\"[INFO] Filtradas {len(df_base)}/{before} linhas para threshold={TARGET_THRESHOLD}\")\n",
    "\n",
    "# =========================\n",
    "# Loop SSIM\n",
    "# =========================\n",
    "ref_map = build_ref_map(REFERENCE_IMAGES)\n",
    "ssim_fundo, ssim_inp = [], []\n",
    "\n",
    "print(f\"[INFO] Processando {len(df_base)} imagens para SSIM...\")\n",
    "for i, row in df_base.iterrows():\n",
    "    img_path = EXPERIMENT_DIR / str(row[\"nome_arquivo\"])\n",
    "    if not img_path.exists():\n",
    "        print(f\"[AVISO] ausente: {img_path}\")\n",
    "        ssim_fundo.append(np.nan)\n",
    "        ssim_inp.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # carrega imagem gerada (padrão: tamanho original)\n",
    "    img_arr = load_img(img_path, RESIZE_TO)\n",
    "\n",
    "    # refs fundo\n",
    "    fundo_refs = find_refs(str(row[\"prompt_fundo\"]), ref_map)\n",
    "    if not fundo_refs:\n",
    "        print(f\"[AVISO] sem ref fundo para: {row['prompt_fundo']}\")\n",
    "        ssim_fundo.append(np.nan)\n",
    "    else:\n",
    "        vals = []\n",
    "        for rp in fundo_refs:\n",
    "            ref_arr = load_img(rp, RESIZE_TO if RESIZE_TO else img_arr.shape[1::-1])\n",
    "            vals.append(ssim_img(img_arr, ref_arr))\n",
    "        ssim_fundo.append(float(np.mean(vals)))\n",
    "\n",
    "    # refs inpainting\n",
    "    inp_refs = find_refs(str(row[\"prompt_roupa\"]), ref_map)\n",
    "    if not inp_refs:\n",
    "        print(f\"[AVISO] sem ref inpainting para: {row['prompt_roupa']}\")\n",
    "        ssim_inp.append(np.nan)\n",
    "    else:\n",
    "        vals = []\n",
    "        for rp in inp_refs:\n",
    "            ref_arr = load_img(rp, RESIZE_TO if RESIZE_TO else img_arr.shape[1::-1])\n",
    "            vals.append(ssim_img(img_arr, ref_arr))\n",
    "        ssim_inp.append(float(np.mean(vals)))\n",
    "\n",
    "    if (len(ssim_fundo) % max(1, len(df_base)//20)) == 0:\n",
    "        print(f\"[INFO] {len(ssim_fundo)}/{len(df_base)} concluídas...\")\n",
    "\n",
    "# =========================\n",
    "# Salva\n",
    "# =========================\n",
    "df_out_ssim = df_base.copy()\n",
    "df_out_ssim[\"ssim_fundo\"] = ssim_fundo\n",
    "df_out_ssim[\"ssim_inpainting\"] = ssim_inp\n",
    "\n",
    "# Se já existe um experiment_metrics.csv com outras métricas, fazemos merge por nome_arquivo\n",
    "try:\n",
    "    if Path(CSV_OUT).exists():\n",
    "        old = pd.read_csv(CSV_OUT)\n",
    "        merged = old.merge(\n",
    "            df_out_ssim[[\"nome_arquivo\", \"ssim_fundo\", \"ssim_inpainting\"]],\n",
    "            on=\"nome_arquivo\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        merged.to_csv(CSV_OUT, index=False)\n",
    "        print(f\"[FINALIZADO] SSIM salvo/mesclado em: {CSV_OUT}\")\n",
    "    else:\n",
    "        df_out_ssim.to_csv(CSV_OUT, index=False)\n",
    "        print(f\"[FINALIZADO] SSIM salvo em: {CSV_OUT}\")\n",
    "except Exception as e:\n",
    "    df_out_ssim.to_csv(CSV_OUT, index=False)\n",
    "    print(f\"[FINALIZADO] SSIM salvo (modo fallback) em: {CSV_OUT}. Motivo do fallback: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97109e90-aed6-4b87-8b9c-10e7bc269913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
