{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "background_map = {\n",
        "    'The city of London': 'The city of London World',\n",
        "    'The Parthenon in front of the Great Pyramid': 'The Parthenon in front of the Great Pyramid',\n",
        "    'A single beam of light enters the room from the ceiling The beam of light is illuminating an easel On the easel there is a Rembrandt painting of a raccoon': 'A single beam of light enters the room from the ceiling. The beam of light is illuminating an easel. On the easel, there is a Rembrandt painting of a raccoon.',\n",
        "    'A sunset': 'A sunset',\n",
        "    'Photograph of a wall along a city street with a watercolor mural of foes in a jazz band': 'Photograph of a wall along a city street with a watercolor mural of foxes in a jazz band.'\n",
        "}\n",
        "\n",
        "clothes_map = {\n",
        "    'A_scientist': 'A scientist',\n",
        "    'A_photograph_of_a_knight_in_shining_armor_holding_a_basketball': 'A photograph of a knight in shining armor holding a basketball',\n",
        "    'The_Mona_Lisa': 'The Mona Lisa',\n",
        "    'Salvador_Dal\u00ed': 'Salvador Dal\u00ed',\n",
        "    'A_person_with_arms_like_a_tree_branch': 'A person with arms like a tree branch'\n",
        "}\n",
        "\n",
        "def parse_threshold(th_str: str) -> float:\n",
        "    return int(th_str[2:]) / 10.0\n",
        "\n",
        "rows = []\n",
        "for file in sorted(Path('experiment').glob('*.jpg')):\n",
        "    name = file.name\n",
        "    parts = name[:-4].split('__')\n",
        "    img_name = parts[0]\n",
        "    background_raw = parts[2]\n",
        "    th_raw = parts[3]\n",
        "    clothing_raw = parts[4]\n",
        "    row = {\n",
        "        'nome_arquivo': name,\n",
        "        'imagem': img_name,\n",
        "        'threshold': parse_threshold(th_raw),\n",
        "        'prompt_fundo': background_map.get(background_raw, background_raw),\n",
        "        'prompt_roupa': clothes_map.get(clothing_raw, clothing_raw.replace('_', ' '))\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "from torchvision.metrics import FrechetInceptionDistance\n",
        "\n",
        "REFERENCE_IMAGES = {\n",
        "    'Photograph of a wall along a city street with a watercolor mural of foxes in a jazz band.': 'reference_images/fox_mural.png',\n",
        "    'The city of London World': 'reference_images/london.png',\n",
        "    'The Parthenon in front of the Great Pyramid': 'reference_images/partenon_great_pyramid.png',\n",
        "    'A sunset': 'reference_images/sunset.png',\n",
        "    'A single beam of light enters the room from the ceiling. The beam of light is illuminating an easel. On the easel, there is a Rembrandt painting of a raccoon.': 'reference_images/racoon.png',\n",
        "    'A scientist': 'reference_images/scientist.png',\n",
        "    'A photograph of a knight in shining armor holding a basketball': 'reference_images/knight_basketball.png',\n",
        "    'The Mona Lisa': 'reference_images/monalisa.jpg',\n",
        "    'Salvador Dal\u00ed': 'reference_images/salvador_dali.jpeg',\n",
        "    'A person with arms like a tree branch': 'reference_images/tree_arms.png'\n",
        "}\n",
        "\n",
        "fid_transform = None\n",
        "\n",
        "def setup_fid_transform():\n",
        "    global fid_transform\n",
        "    fid_transform = T.Compose([T.Resize((299, 299)), T.ToTensor()])\n",
        "\n",
        "def compute_clip_score(image_path, prompt, model, preprocess, device):\n",
        "    image = preprocess(Image.open(image_path).convert('RGB')).unsqueeze(0).to(device)\n",
        "    text = clip.tokenize([prompt]).to(device)\n",
        "    with torch.no_grad():\n",
        "        img_feat = model.encode_image(image)\n",
        "        txt_feat = model.encode_text(text)\n",
        "        img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
        "        txt_feat /= txt_feat.norm(dim=-1, keepdim=True)\n",
        "        score = (img_feat @ txt_feat.T).squeeze().cpu().item()\n",
        "    return float(score)\n",
        "\n",
        "def compute_fid(image_path, ref_path, fid_metric):\n",
        "    if fid_transform is None:\n",
        "        setup_fid_transform()\n",
        "    img = fid_transform(Image.open(image_path).convert('RGB')).unsqueeze(0)\n",
        "    ref = fid_transform(Image.open(ref_path).convert('RGB')).unsqueeze(0)\n",
        "    fid_metric.reset()\n",
        "    fid_metric.update(ref, real=True)\n",
        "    fid_metric.update(img, real=False)\n",
        "    return float(fid_metric.compute().item())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model, preprocess = clip.load('ViT-B/32', device=device)\n",
        "fid_metric = FrechetInceptionDistance(feature=64)\n",
        "\n",
        "max_images = None  # set to an int to limit processing for tests\n",
        "df_proc = df if max_images is None else df.head(max_images)\n",
        "\n",
        "clip_scores = []\n",
        "fid_scores = []\n",
        "for _, row in df_proc.iterrows():\n",
        "    img_path = Path('experiment') / row['nome_arquivo']\n",
        "    text_prompt = f\"{row['prompt_roupa']} in {row['prompt_fundo']}\"\n",
        "    clip_score = compute_clip_score(img_path, text_prompt, model, preprocess, device)\n",
        "    back_ref = Path(REFERENCE_IMAGES[row['prompt_fundo']])\n",
        "    cloth_ref = Path(REFERENCE_IMAGES[row['prompt_roupa']])\n",
        "    fid_back = compute_fid(img_path, back_ref, fid_metric)\n",
        "    fid_cloth = compute_fid(img_path, cloth_ref, fid_metric)\n",
        "    clip_scores.append(clip_score)\n",
        "    fid_scores.append((fid_back + fid_cloth) / 2.0)\n",
        "\n",
        "df_proc = df_proc.copy()\n",
        "df_proc['clip_score'] = clip_scores\n",
        "df_proc['fid'] = fid_scores\n",
        "df = df.merge(df_proc[['nome_arquivo','clip_score','fid']], on='nome_arquivo', how='left')\n",
        "\n",
        "df.to_csv('experiment_metrics.csv', index=False)\n",
        "df.head()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "threshold_metrics = df.groupby('threshold')[['clip_score','fid']].mean().reset_index()\n",
        "threshold_metrics\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(10,4), sharex=True)\n",
        "axes[0].plot(threshold_metrics['threshold'], threshold_metrics['clip_score'], marker='o')\n",
        "axes[0].set_title('CLIP Score')\n",
        "axes[0].set_xlabel('threshold')\n",
        "axes[0].set_ylabel('score')\n",
        "\n",
        "axes[1].plot(threshold_metrics['threshold'], threshold_metrics['fid'], marker='o', color='orange')\n",
        "axes[1].set_title('FID')\n",
        "axes[1].set_xlabel('threshold')\n",
        "axes[1].set_ylabel('score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}